{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word arithmetic\n",
    "In this practice notebook, we'll explore how you can calculate with word embeddings.\n",
    "\n",
    "If needed (e.g. on Google Colab), first install the necessary packages and download the correct model by uncommenting the following two cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordfreq spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8vW9svTE289D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "import numpy as np\n",
    "from wordfreq import zipf_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors are only available in larger models, so let's load that first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mWDrpxDk2_r2"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "s = \"It's not about the money (only $20.15), it's about sending a message :). ðŸš€ðŸ’ŽðŸ™Œ\"\n",
    "doc = nlp(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "money"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[5]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.3163e+00,  9.7209e+00, -3.1254e+00, -5.1013e+00,  1.2248e+01,\n",
       "        7.4676e-01, -2.2017e+00,  7.7449e+00,  7.7495e+00,  2.4786e+00,\n",
       "        2.9003e+00, -8.2717e+00, -1.8624e+00, -2.5267e+00, -2.4342e+00,\n",
       "        9.2120e+00,  3.2893e+00,  4.1051e+00,  8.4594e+00,  6.1904e+00,\n",
       "        4.0433e+00, -8.7288e+00, -5.1290e-01, -4.1820e+00,  5.4291e-01,\n",
       "        4.1663e+00, -4.1425e+00, -3.5223e+00,  5.6047e+00,  6.7570e-01,\n",
       "       -8.4769e+00,  7.1013e+00,  3.6598e+00, -3.7614e+00, -6.9369e+00,\n",
       "        2.2243e+00, -1.9601e+00,  7.1614e+00, -5.6895e+00,  2.1034e+00,\n",
       "       -5.8237e+00,  2.7890e+00, -2.9914e+00, -4.0231e+00, -4.2667e+00,\n",
       "       -7.5207e-01,  4.5451e-01, -8.6609e+00, -1.7533e+00,  1.0410e+01,\n",
       "       -2.7430e+00,  3.3978e-01,  8.1811e+00,  4.2430e+00,  6.6655e+00,\n",
       "       -9.3432e+00,  1.7088e+00, -5.9095e+00,  4.9347e-01,  2.3570e+00,\n",
       "        3.8203e+00, -5.9410e+00,  1.2467e+00, -1.5427e+00,  4.3948e+00,\n",
       "       -2.0103e+00, -6.6615e-01, -2.7626e+00,  5.2211e+00, -6.8312e+00,\n",
       "       -3.0608e+00,  5.8089e-01, -1.0792e+01, -8.3716e-01,  4.0435e+00,\n",
       "       -3.8296e+00, -3.5472e-01,  5.8879e+00, -1.1180e+00, -1.2660e+00,\n",
       "       -8.7758e+00, -2.9683e+00, -1.4634e+00,  1.2161e+00,  6.1365e+00,\n",
       "       -2.9043e+00, -8.2843e+00, -8.5882e+00,  1.1055e+00, -1.7437e+00,\n",
       "       -8.1566e+00, -4.4753e+00, -4.2367e+00, -8.3422e+00,  5.2278e+00,\n",
       "       -8.7971e+00, -3.2541e+00, -6.2841e+00,  2.7286e+00, -1.2128e+01,\n",
       "        8.9992e-01,  1.3155e-01,  1.3093e+00,  1.1122e+01,  9.1852e-01,\n",
       "        2.7730e+00,  3.0919e+00,  6.3933e+00, -1.1579e+00,  3.0251e+00,\n",
       "       -7.9088e+00,  8.3546e+00, -6.0805e+00, -1.0248e-02,  3.2102e+00,\n",
       "       -7.4278e+00,  6.8271e+00,  4.2424e+00, -8.5219e+00,  2.6071e+00,\n",
       "       -5.6361e+00, -2.2631e+00,  3.1832e+00,  5.4920e-01,  7.2047e-01,\n",
       "        4.6217e+00,  2.0564e+00,  3.9871e+00,  4.0672e+00, -2.6514e+00,\n",
       "       -1.3561e+00, -7.4539e+00,  1.9593e+00, -8.9433e+00, -1.1885e+00,\n",
       "       -2.3575e+00,  2.0626e+00, -4.4911e-01,  4.8528e+00, -8.8703e+00,\n",
       "       -5.7906e+00, -3.3864e-01,  5.7103e+00,  6.4773e+00,  3.9029e+00,\n",
       "        4.5020e+00, -1.2325e+01,  1.0540e+00,  1.0190e+01,  7.8896e+00,\n",
       "        6.4595e-01, -1.3175e+00,  8.4803e+00,  4.1650e+00, -4.5549e+00,\n",
       "        3.2959e+00, -8.3156e-01,  4.0501e+00, -2.9822e+00,  2.5656e-01,\n",
       "        2.3249e+00, -7.1629e+00, -1.7492e+00,  1.9339e-01, -8.2704e+00,\n",
       "       -2.8786e+00,  3.4320e-01,  7.1602e+00, -3.5060e+00,  4.3321e-01,\n",
       "        6.3689e+00, -5.9433e+00,  1.1253e+01, -2.2913e+00, -2.7121e+00,\n",
       "       -2.7680e+00,  8.8242e-01,  5.3598e+00,  6.6881e+00, -5.4231e+00,\n",
       "       -1.3903e+00,  1.3222e+01,  6.0751e+00,  9.6260e+00, -1.8019e-01,\n",
       "       -5.0338e+00,  4.2176e+00, -3.6242e+00,  1.7922e+00, -9.2969e-01,\n",
       "       -6.6352e-01, -1.4758e+00,  2.5704e+00, -1.1869e+00, -4.3529e+00,\n",
       "       -3.2915e+00,  3.4649e-01,  6.9080e+00,  5.3615e+00, -1.9832e+00,\n",
       "       -5.4000e-01, -4.3030e+00, -6.2865e-01, -7.2286e+00,  3.2205e+00,\n",
       "        8.8048e+00, -5.5753e+00,  2.9940e+00, -5.9683e+00, -6.7345e-01,\n",
       "       -2.8473e+00,  5.9040e+00, -8.4362e-01,  2.4392e-01, -6.1087e-01,\n",
       "        6.3019e-01, -4.6680e+00,  6.0982e+00,  5.0798e+00, -2.3543e+00,\n",
       "        3.8486e-01, -3.1862e+00, -1.2552e+00,  3.8295e+00, -5.3580e+00,\n",
       "        5.9380e+00,  7.0337e+00,  4.3981e+00,  1.0604e+00,  9.2235e-01,\n",
       "        6.9878e-01, -6.8657e+00, -5.8964e+00,  1.8174e+00, -1.2808e-01,\n",
       "        6.6556e+00, -1.7575e+00,  8.4075e-01,  2.8712e+00,  1.2854e+00,\n",
       "       -2.3327e+00,  6.1019e+00,  5.4645e-01,  1.5120e+00, -6.2882e+00,\n",
       "        3.6760e+00, -8.2726e+00, -3.9754e+00, -1.3360e+00,  8.6808e+00,\n",
       "       -1.9546e+00, -6.0275e+00, -3.3511e+00, -4.2063e+00,  2.3947e+00,\n",
       "       -2.3970e+00,  6.8777e+00, -3.9782e+00, -3.3170e+00,  2.6976e+00,\n",
       "       -6.4074e+00, -1.9875e-01, -3.6334e-01,  7.8088e+00,  8.1748e-01,\n",
       "        7.4245e+00,  3.0908e+00,  1.6293e-01,  6.6846e-01,  4.4809e+00,\n",
       "        5.2782e+00,  7.7008e-01, -4.2395e+00, -1.6641e+00,  2.7196e+00,\n",
       "        4.2927e+00,  4.6326e+00, -1.9226e+00,  6.8999e+00,  7.9010e+00,\n",
       "       -1.0689e+01,  1.2505e+00, -8.7035e+00, -1.1378e+00,  4.2230e+00,\n",
       "        6.0686e+00,  8.8893e+00,  8.7867e-01,  4.4649e-01,  8.7634e-01,\n",
       "        3.9221e+00, -1.5153e+00,  1.9848e+00,  2.6245e+00, -5.1080e+00,\n",
       "        7.0160e-01, -2.5287e+00,  5.0545e+00,  5.3875e+00,  3.1216e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[1]\n",
    "token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.vector.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_id(word: str):\n",
    "    return nlp.vocab.strings[word]\n",
    "\n",
    "def get_vector(word: str):\n",
    "    return nlp.vocab.vectors[get_vocab_id(word)]\n",
    "\n",
    "def get_token(word: str):\n",
    "    return nlp(word)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4756779074668884"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token(\"woman\").similarity(get_token(\"queen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat cat 1.0\n",
      "cat lion 0.3854507803916931\n",
      "cat pet 0.732966423034668\n",
      "lion cat 0.3854507803916931\n",
      "lion lion 1.0\n",
      "lion pet 0.20031583309173584\n",
      "pet cat 0.732966423034668\n",
      "pet lion 0.20031583309173584\n",
      "pet pet 1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'cat lion pet')\n",
    "\n",
    "for t1 in tokens:\n",
    "    for t2 in tokens:\n",
    "        print(t1.text,t2.text,t1.similarity(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "castle, castle, 1.000\n",
      "castle, king, 0.494\n",
      "castle, student, -0.021\n",
      "castle, error, 0.015\n",
      "king, castle, 0.494\n",
      "king, king, 1.000\n",
      "king, student, 0.201\n",
      "king, error, 0.155\n",
      "student, castle, -0.021\n",
      "student, king, 0.201\n",
      "student, student, 1.000\n",
      "student, error, 0.109\n",
      "error, castle, 0.015\n",
      "error, king, 0.155\n",
      "error, student, 0.109\n",
      "error, error, 1.000\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'castle king student error')\n",
    "\n",
    "for t1 in tokens:\n",
    "    for t2 in tokens:\n",
    "        print(f\"{t1.text}, {t2.text}, {t1.similarity(t2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most similar words to a given vector\n",
    "Documentation https://spacy.io/api/vectors#most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(vec: np.ndarray, include_rare = False):\n",
    "    # vec = vector(word)\n",
    "\n",
    "    vocab_ids = nlp.vocab.vectors.most_similar(np.asarray([vec]), n=100)\n",
    "    words =  [nlp.vocab.strings[w] for w in vocab_ids[0][0]]\n",
    "    if include_rare:\n",
    "        return [w for w in words if get_token(w).is_alpha][0:20]\n",
    "    else:\n",
    "        return [w for w in words if get_token(w).is_alpha & (zipf_frequency(w, \"en\", wordlist='small', minimum=1)> 3)][0:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'physician',\n",
       " 'psychiatrist',\n",
       " 'doctors',\n",
       " 'dentist',\n",
       " 'nurse',\n",
       " 'pharmacist',\n",
       " 'pediatrician',\n",
       " 'surgeon',\n",
       " 'proctor',\n",
       " 'dermatologist',\n",
       " 'veterinarian',\n",
       " 'midwife',\n",
       " 'psychiatrists',\n",
       " 'therapist',\n",
       " 'neurologist',\n",
       " 'clinic',\n",
       " 'medic',\n",
       " 'Pediatrician',\n",
       " 'physicians']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"doctor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['king',\n",
       " 'princess',\n",
       " 'princesses',\n",
       " 'princes',\n",
       " 'prince',\n",
       " 'kings',\n",
       " 'queen',\n",
       " 'consort',\n",
       " 'Mcqueen',\n",
       " 'mcqueen',\n",
       " 'monarch',\n",
       " 'ruler',\n",
       " 'rulers',\n",
       " 'Princesses',\n",
       " 'thrones',\n",
       " 'kingdom',\n",
       " 'monarchs',\n",
       " 'throne',\n",
       " 'kingdoms',\n",
       " 'royal']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"king\") - get_vector(\"man\") + get_vector(\"girl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'pediatrician',\n",
       " 'nurse',\n",
       " 'midwife',\n",
       " 'physician',\n",
       " 'Pediatrician',\n",
       " 'dermatologist',\n",
       " 'dentist',\n",
       " 'therapist',\n",
       " 'Dermatologist',\n",
       " 'clinic',\n",
       " 'pharmacist',\n",
       " 'doctors',\n",
       " 'Midwife',\n",
       " 'pediatrics',\n",
       " 'psychiatrist',\n",
       " 'veterinarian',\n",
       " 'pediatric',\n",
       " 'neurologist',\n",
       " 'Physician']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"doctor\") - get_vector(\"man\") + get_vector(\"woman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['student',\n",
       " 'campus',\n",
       " 'school',\n",
       " 'dormitory',\n",
       " 'university',\n",
       " 'castle',\n",
       " 'students',\n",
       " 'classmate',\n",
       " 'pupil',\n",
       " 'teacher',\n",
       " 'classroom',\n",
       " 'headmaster',\n",
       " 'undergraduate',\n",
       " 'college',\n",
       " 'Dormitory',\n",
       " 'undergraduates',\n",
       " 'gymnasium',\n",
       " 'schoolboy',\n",
       " 'pupils',\n",
       " 'highschool']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"castle\") - get_vector(\"royalty\") + get_vector(\"student\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tokyo'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"Berlin\") - get_vector(\"Germany\") + get_vector(\"Japan\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cold',\n",
       " 'colder',\n",
       " 'drier',\n",
       " 'warmer',\n",
       " 'cooler',\n",
       " 'milder',\n",
       " 'freezing',\n",
       " 'temperatures',\n",
       " 'dry',\n",
       " 'frosty',\n",
       " 'frost',\n",
       " 'temperature',\n",
       " 'temperate',\n",
       " 'damp',\n",
       " 'chilly',\n",
       " 'humid',\n",
       " 'warms',\n",
       " 'warmed',\n",
       " 'heat',\n",
       " 'Colder']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"bigger\") - get_vector(\"big\") + get_vector(\"cold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toulouse', 'marseille', 'fries', 'Provence']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"sushi\") - get_vector(\"Japan\") + get_vector(\"France\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trudeau',\n",
       " 'Merkel',\n",
       " 'merkel',\n",
       " 'Abbott',\n",
       " 'Sturgeon',\n",
       " 'Truss',\n",
       " 'McConnell',\n",
       " 'Canada',\n",
       " 'Turnbull',\n",
       " 'Thatcher',\n",
       " 'Ontario',\n",
       " 'Alberta',\n",
       " 'NDP',\n",
       " 'Johnson',\n",
       " 'Manitoba',\n",
       " 'Hancock',\n",
       " 'Lawmaker',\n",
       " 'McGill',\n",
       " 'Ottawa',\n",
       " 'Blair']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"Merkel\") - get_vector(\"Germany\") + get_vector(\"Canada\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "- Library for embedding exploration: https://github.com/koaning/whatlies/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Vlerick-MAI-NLP-demo.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
